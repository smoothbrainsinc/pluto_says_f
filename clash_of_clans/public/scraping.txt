**Web Scraping Guide for Parrot OS**

## **1. Setting Up Your Environment**

### **1.1 Install Required Packages**
Run the following command to install Python, Pip, and necessary libraries:
```bash
sudo apt update && sudo apt install -y python3 python3-pip firefox-esr
pip3 install selenium beautifulsoup4 requests lxml
```

### **1.2 Install Geckodriver (for Selenium with Firefox)**
```bash
wget https://github.com/mozilla/geckodriver/releases/download/v0.34.0/geckodriver-v0.34.0-linux64.tar.gz
tar -xvzf geckodriver-v0.34.0-linux64.tar.gz
sudo mv geckodriver /usr/local/bin/
rm geckodriver-v0.34.0-linux64.tar.gz
```
Check if Geckodriver is installed:
```bash
geckodriver --version
```

---

## **2. Basic Web Scraping with Requests and BeautifulSoup**
This method works for static pages (no JavaScript rendering).

### **2.1 Simple Static Page Scraping**
```python
import requests
from bs4 import BeautifulSoup

url = "https://example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# Extracting all links
for link in soup.find_all("a"):
    print(link.get("href"))
```

---

## **3. Handling JavaScript-Rendered Pages with Selenium**
For dynamic pages (e.g., loading data with JavaScript), use Selenium.

### **3.1 Open a Web Page with Selenium**
```python
from selenium import webdriver

driver = webdriver.Firefox()
driver.get("https://example.com")
print(driver.title)
driver.quit()
```

### **3.2 Extract Data from a Dynamic Table**
```python
from selenium import webdriver
from bs4 import BeautifulSoup
import time

options = webdriver.FirefoxOptions()
options.add_argument("--headless")  # Runs in the background
driver = webdriver.Firefox(options=options)
driver.get("https://clashofclans.fandom.com/wiki/Clash_of_Clans_Wiki")

time.sleep(5)  # Wait for JavaScript to load
soup = BeautifulSoup(driver.page_source, "html.parser")

table_data = soup.find_all("td", class_=["ModifierStat DPS", "ModifierStat DPH", "ModifierStat HP", "GoldPass rCost", "GoldPass rTime"])
for td in table_data:
    print(td.text.strip())

driver.quit()
```

---

## **4. Bypassing Anti-Scraping Measures**
Some sites block scrapers. Here’s how to avoid detection:

### **4.1 Set a User-Agent**
```python
headers = {"User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36"}
response = requests.get(url, headers=headers)
```

### **4.2 Use Proxies**
```python
proxies = {"http": "http://your-proxy.com", "https": "https://your-proxy.com"}
response = requests.get(url, headers=headers, proxies=proxies)
```

---

## **5. Saving Data to a File**
### **5.1 Save to CSV**
```python
import csv

data = [["Name", "DPS", "HP"], ["Troop1", "34", "60"]]
with open("output.csv", "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerows(data)
```

### **5.2 Save to JSON**
```python
import json

data = {"troop": "Troop1", "DPS": 34, "HP": 60}
with open("output.json", "w") as f:
    json.dump(data, f, indent=4)
```

---

## **6. Debugging Common Errors**
### **6.1 Geckodriver Not Found**
Run:
```bash
echo $PATH
ls /usr/local/bin/ | grep geckodriver
```
If missing, reinstall Geckodriver.

### **6.2 "Element Not Found" Error**
Try increasing wait time:
```python
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

wait = WebDriverWait(driver, 10)
element = wait.until(EC.presence_of_element_located((By.CLASS_NAME, "ModifierStat DPS")))
```

---

## **7. Further Learning Resources (PDFs Available)**
- **Automate the Boring Stuff with Python (2019)** – [Download](https://automatetheboringstuff.com/2e/chapter12/)
- **Web Scraping with Python (O’Reilly, 2017)** – [Download](https://riptutorial.com/Download/web-scraping-with-python.pdf)
- **Python Web Scraping Cookbook (2018)** – [Download](https://www.dbooks.org/python-web-scraping-cookbook-1787285212/)
- **Scrapy Documentation (Updated Regularly)** – [Download](https://docs.scrapy.org/en/latest/_downloads/scrapy.pdf)
- **BeautifulSoup Cheat Sheet** – [Download](https://ehmatthes.github.io/pcc/cheat_sheets/bs4_cheat_sheet.pdf)

---

This guide gives you everything you need to start web scraping **on Parrot OS** without unnecessary fluff. Let me know if you need any modifications or if you want this exported as a **PDF**.

